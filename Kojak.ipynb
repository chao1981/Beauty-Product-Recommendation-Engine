{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from bson.son import SON\n",
    "from bson.code import Code\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "# These are packages need for natural language processing:\n",
    "import nltk\n",
    "from __future__ import division, unicode_literals \n",
    "from textblob import TextBlob as tb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "#creating mbf database (mbf = \"meta beauty file\")\n",
    "mbf = client.dsbc.mbf\n",
    "# mbf.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('meta_Beauty.json') as meta_beauty_file:\n",
    "    for line in meta_beauty_file:\n",
    "        meta_f = json.loads(line)  \n",
    "        #only work when using json.loads() not json.load() \n",
    "        mbf.insert(meta_f)\n",
    "        \n",
    "#can't do json.load(meta_beautfy_file) since meta_beauty_file has the form \"{...}{...}{...}\" --> not json\n",
    "#json.load(line) does not work since line is  string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"categories\": [[\"Beauty\", \"Skin Care\",...]] --> need to $unwind\n",
    "# use \"categories.0\" get the innner list.\n",
    "\n",
    "#Skin_care = mbf.find({\"categories.0\": [\"Beauty\"]})\n",
    "\n",
    "pipeline  = [{\"$unwind\":\"$categories\"},\n",
    "             {\"$match\":{\"categories\":{\"$all\":[\"Face\",\"Creams & Moisturizers\"]}}},\n",
    "             {\"$project\":{\"_id\":0,\"asin\":1,\"title\":1,\"price\":1}},\n",
    "             {\"$out\": \"product_info\"}]\n",
    "# \"$out\" write the result into new collection\n",
    "# \"$all\" find all list that contains everything in queries\n",
    "mbf.aggregate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_info = client.dsbc.product_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# name = product_info.find({}, {\"_id\":0,\"asin\":1})\n",
    "# id_list  = {}\n",
    "# for id_num in name:\n",
    "#     id_list.append(id_num[\"asin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = product_info.find({}, {\"_id\":0,\"asin\":1,\"title\":1,\"price\":1})\n",
    "id_list  = {}\n",
    "for id_num in name:\n",
    "    try:\n",
    "        id_list[id_num[\"asin\"]]=[id_num[\"title\"],id_num[\"price\"]]\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#id_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating database for reviews beauty file\n",
    "rbf = client.dsbc.rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('reviews_Beauty.json') as reviews_beauty_file:\n",
    "    for line in reviews_beauty_file:\n",
    "        review = json.loads(line)  \n",
    "        rbf.insert(review)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new database for selective items\n",
    "ndb = client.dsbc.ndb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beauty_item_tb = {id_list.keys()[0] : id_list.values()[0], \n",
    "                    \"Reviews\" : [], \"rating\":{\"Five_star\":0, \n",
    "                                              \"Four_star\":0,\n",
    "                                              \"Three_star\":0,\n",
    "                                              \"Two_star\":0,\n",
    "                                              \"One_star\":0}}\n",
    "match_list = rbf.find({\"asin\":{\"$in\": [id_list.keys()[0]]}})\n",
    "\n",
    "for i in match_list:\n",
    "    beauty_item_tb[\"Reviews\"].append(tb(i['reviewText']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TF-IDF method\n",
    "\n",
    "tf(word, blob) computes \"term frequency\" which is the number of times a word appears in a document blob, normalized by dividing by the total number of words in blob. We use TextBlob for breaking up the text into words and getting the word counts.\n",
    "\n",
    "n_containing(word, bloblist) returns the number of documents containing word. A generator expression is passed to the sum() function.\n",
    "\n",
    "idf(word, bloblist) computes \"inverse document frequency\" which measures how common a word is among all documents in bloblist. The more common a word is, the lower its idf. We take the ratio of the total number of documents to the number of documents containing word, then take the log of that. Add 1 to the divisor to prevent division by zero.\n",
    "tfidf(word, blob, bloblist) computes the TF-IDF score. It is simply the product of tf and idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Sentiment(polarity=0.3722222222222222, subjectivity=0.6432098765432098)\n",
      "1 Sentiment(polarity=0.2, subjectivity=0.6)\n"
     ]
    }
   ],
   "source": [
    "for i, blob in enumerate(beauty_item_info['Reviews']):\n",
    "    print i, blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextBlob(\"I just started using this, so I'm not sure yet of the long-term effects, but overall it's a great moisturizer.  I'm fairly picky about moisturizers, since I tend to be really oily (my whole face, too...lucky me).  This one seems like it might be a winner.  It absorbed nicely and my skin did look and feel great after using it. It did lose one star, though, because of the price- it's a bit steep.\"),\n",
       " TextBlob(\"I bought it for a collagen moisturizer and immediately found it cleared my breakouts. I still use an under eye cream since I am 56 but this cream is miraculous. It soaks in so fast you can't believe it and it not greasy or shiny for someone with oily skin.\")]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beauty_item_info['Reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: winner, TF-IDF: 0.0\n",
      "\tWord: just, TF-IDF: 0.0\n",
      "\tWord: feel, TF-IDF: 0.0\n",
      "\tWord: look, TF-IDF: 0.0\n",
      "\tWord: because, TF-IDF: 0.0\n",
      "\tWord: star, TF-IDF: 0.0\n",
      "\tWord: tend, TF-IDF: 0.0\n",
      "\tWord: really, TF-IDF: 0.0\n",
      "\tWord: to, TF-IDF: 0.0\n",
      "\tWord: seems, TF-IDF: 0.0\n",
      "Top words in document 2\n",
      "\tWord: breakouts, TF-IDF: 0.0\n",
      "\tWord: am, TF-IDF: 0.0\n",
      "\tWord: soaks, TF-IDF: 0.0\n",
      "\tWord: someone, TF-IDF: 0.0\n",
      "\tWord: still, TF-IDF: 0.0\n",
      "\tWord: cream, TF-IDF: 0.0\n",
      "\tWord: believe, TF-IDF: 0.0\n",
      "\tWord: eye, TF-IDF: 0.0\n",
      "\tWord: for, TF-IDF: 0.0\n",
      "\tWord: fast, TF-IDF: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, blob in enumerate(beauty_item_tb['Reviews']):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, beauty_item_tb['Reviews']) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Based on the above analysis, we can see that it's not very helpful to look at TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_b_product (i):\n",
    "    beauty_item_info = {id_list.keys()[i] : id_list.values()[i], \n",
    "                    \"Reviews\" : '', \"rating\":{\"Five_star\":0, \n",
    "                                              \"Four_star\":0,\n",
    "                                              \"Three_star\":0,\n",
    "                                              \"Two_star\":0,\n",
    "                                              \"One_star\":0}}\n",
    "    match_list = rbf.find({\"asin\":{\"$in\": [id_list.keys()[i]]}})\n",
    "\n",
    "    for i in match_list:\n",
    "        beauty_item_info[\"Reviews\"]+=(i['reviewText'])\n",
    "        if i['overall'] == 5.0:\n",
    "            beauty_item_info[\"rating\"][\"Five_star\"] += 1\n",
    "        elif i['overall'] == 4.0:\n",
    "            beauty_item_info[\"rating\"][\"Four_star\"] += 1\n",
    "        elif i['overall'] == 3.0:\n",
    "            beauty_item_info[\"rating\"][\"Three_star\"] += 1\n",
    "        elif i['overall'] == 2.0:\n",
    "            beauty_item_info[\"rating\"][\"Two_star\"] += 1\n",
    "        else:\n",
    "            beauty_item_info[\"rating\"][\"One_star\"] += 1\n",
    "    return beauty_item_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'B002FP4ADG': [u'Decleor Hydra Floral Moisturizing Cream - Tube 1.35 oz.',\n",
       "  47.88],\n",
       " u'Reviews': u\"Great service, my order arrived earlier than the expected 7-10 day shipping through USPS. I have used this product before and love it. I was happy to find this great deal through Amazon. I ordered two of these moisturizers and the Decleor boxes that the moisturizers came in were a little dinged up after making their way through US mail, but the jars inside were not damaged at all, so  I have no complaints. Would recommend this seller!The pros: You use a very tiny little bit, and it goes a long way. Feels very non-greasy but still quenches my skin's thirst.The con: Price. Although obviously you could do worse, this does cost more than other brands.All in all, I love this moisturizer and have been using it for years.I'm fussy about what I put on my 47 year old face these days. Luckily good family genes help me to look younger than my years, but I still moisturize and use sun screen. Being older and wiser helps me not to foolishly spend $ on face cream. I don't need or use 5 different ones or one for every problem. But this Hydra Floral cream is the best for me! Love the scent and best of all it's effective and a little goes a long way. A 1.7oz jar can last me a year. I ordered last time from 123Skincare, and I promised to give them a good review after a bumpy start to my order that they quickly replied to.  They were very interested in me being happy, and because of that I will order from them again!This cream is such a total waste of money. Your better off at the drug store!Sad but true, labeling is such a market strategy.I would give this 0 stars if I could because I ordered 'Hydra Floral Anti-Pollution&#34; but I received the &#34;Hydra Floral Multi-Protection&#34; face creme which is much thicker and has a completely different scent. It also does not moisturize my face as well, despite being thicker.I absolutely love the Hydra Floral face creme and have been using it for years - and have even ordered it from Amazon before without issue - so imagine my shock and disappointment when I received the wrong face creme and then found that Amazon does not allow this type of product to be returned. I understand that the small print of the product description says &#34;(Due to a manufacturer packaging change, item received may vary from photograph.)&#34; but IMO that should not mean that they can send you a completely different product than the one advertised and ordered. A different box or jar, sure, but not a completely DIFFERENT item. Very disappointed and won't be ordering this from Amazon again.\",\n",
       " u'rating': {u'Five_star': 1,\n",
       "  u'Four_star': 2,\n",
       "  u'One_star': 2,\n",
       "  u'Three_star': 0,\n",
       "  u'Two_star': 0}}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_b_product(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100 #number of words to consider\n",
    "Cluster_threshold = 5 #distance between two words to consider\n",
    "Top_sentences = 5 #number of sentences to return for a \"top n\" summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###This approach is based on \"The Automatic Creation of Literature Abstracts\" by H.P.Luhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _score_sentences(sentences, important_words,Cluster_threshold = 5):\n",
    "    scores = []\n",
    "    sentence_idx = -1\n",
    "    \n",
    "    #word_tokenize(s) split a sentence and find all the words and punctuations\n",
    "    for s in [nltk.tokenize.word_tokenize(s) for s in sentences]:\n",
    "        sentence_idx += 1\n",
    "        word_idx =[]\n",
    "        \n",
    "        # This function check whether any important words occur in the sentence\n",
    "        # if  there is, record the location of the important word in the sentence\n",
    "        for w in important_words:\n",
    "            try:\n",
    "                word_idx.append(s.index(w))\n",
    "            except ValueError, e:\n",
    "                pass\n",
    "        word_idx.sort()\n",
    "        \n",
    "        #If there is no important words in the sentence, skip the rest of the loop\n",
    "        #and goes on to next sentence\n",
    "        if len(word_idx) == 0 : continue\n",
    "        \n",
    "        #compute clusters by using a max distance threshold for any two consecutive words\n",
    "        clusters = []\n",
    "        cluster = [word_idx[0]]\n",
    "        \n",
    "        i = 1\n",
    "        while i < len(word_idx):\n",
    "            if word_idx[i] - word_idx[i-1] < Cluster_threshold:\n",
    "                cluster.append(word_idx[i])\n",
    "            else:\n",
    "                clusters.append(cluster[:])\n",
    "                cluster = [word_idx[i]]\n",
    "            i += 1\n",
    "        clusters.append(cluster)\n",
    "        \n",
    "        #now score each cluster. The max score for any give cluster is the score for the \n",
    "        #sentence\n",
    "        \n",
    "        max_cluster_score = 0\n",
    "        for c in clusters:\n",
    "            num_important_words_in_cluster = len(c)\n",
    "            total_words_in_cluster = c[-1] - c[0] + 1\n",
    "            score = 1.0 * num_important_words_in_cluster\\\n",
    "                    *(num_important_words_in_cluster/total_words_in_cluster)\n",
    "            \n",
    "            if score > max_cluster_score:\n",
    "                max_cluster_score = score \n",
    "        scores.append((sentence_idx,score))\n",
    "    return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize(txt, N=100, Top_sentences = 5):\n",
    "    # creat a list of sentences from text file and normalize those sentences\n",
    "    sentences = [s.lower() for s in nltk.tokenize.sent_tokenize(txt)]\n",
    "    \n",
    "    #create a list of words from the entire text file\n",
    "    words = [w.lower() for sentence in sentences for w in nltk.tokenize.word_tokenize(sentence)]\n",
    "    fqdist = nltk.FreqDist(words)\n",
    "    \n",
    "    #create a list of stop_words  (word that are not important that they appear)\n",
    "    #because this is a beauty product recommendation app, I don't want the summary\n",
    "    #to talk about the seller or delivery system\n",
    "    stop_words = nltk.corpus.stopwords.words('english') \\\n",
    "                + ['usps','shipping','$','#', \n",
    "                   '&','order','seller','packaging','manufacture',\n",
    "                   'package','cute','delivery', '.',',',\n",
    "                   '?','...']\n",
    "######################################################################    \n",
    "    top_n_words = [w[0] for w in fqdist.items() \n",
    "                  if w[0] not in stop_words][:N]\n",
    "######################################################################\n",
    "\n",
    "#CUSTOMIZE important words:\n",
    "#     top_n_words = ['skin','mosturizer', 'smooth','care', \n",
    "#                   'dry', 'breakout', 'pimples','good',\n",
    "#                   'greasy','effective', 'great','restoration',\n",
    "#                   'expensive', 'cheap','works','relief',\n",
    "#                   'well', 'fast', 'young', 'wrinkle','itching',\n",
    "#                   'awesome','love', 'mosturizing','glow','miracle',\n",
    "#                   'healthy','white','bright','shine','cream','red',\n",
    "#                   'terrible','creams','absorb','smell','smelly','natural',\n",
    "#                   'organic', 'hydrate', 'light', 'effects', 'change', 'soft',\n",
    "#                   'non','inexpensive','worthless', 'wonderful','soothing',\n",
    "#                   'clear', 'dull', 'cheap', 'combination']\n",
    "    \n",
    "    scored_sentences = _score_sentences(sentences, top_n_words)\n",
    "    \n",
    "    #Summarization Approach 1:\n",
    "    avg = np.mean([s[1] for s in scored_sentences])\n",
    "    std = np.std([s[1] for s in scored_sentences])\n",
    "    mean_scored = [(sent_idx, score) for (sent_idx, score) in scored_sentences \n",
    "                    if score > avg + 0.5 *std ]\n",
    "\n",
    "    \n",
    "    #Summarization Approach 2:\n",
    "    top_n_scored = sorted(scored_sentences, key=lambda s: s[1])[-Top_sentences:]\n",
    "    top_n_scored = sorted(top_n_scored, key=lambda s: s[0])\n",
    "    \n",
    "    return dict(top_n_summary=[sentences[idx] for (idx,score) in top_n_scored],\n",
    "                mean_score_summary=[sentences[idx] for (idx,score) in mean_scored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3.02941176471\n",
      "[u\"i just started using this, so i'm not sure yet of the long-term effects, but overall it's a great moisturizer.\", u\"i'm fairly picky about moisturizers, since i tend to be really oily (my whole face, too...lucky me).\", u'it absorbed nicely and my skin did look and feel great after using it.', u\"it did lose one star, though, because of the price- it's a bit steep.i bought it for a collagen moisturizer and immediately found it cleared my breakouts.\", u\"it soaks in so fast you can't believe it and it not greasy or shiny for someone with oily skin.\"]\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u'i am  65 and really like this cream.', u'it has been hard to find something that i feel really improves my skin without being greasy.', u'this is great under makeup and at bed time .', u'i was pleasantly surprised.', u'great price for product compared to other products that i paid much much for without good results.']\n",
      "\n",
      "\n",
      "2\n",
      "3.0\n",
      "[u'its ok.', u\"i don't see that much of a difference in my dryness honestly.\", u\"i don't think i would repurchase.love this product.\", u\"can be a bit greasy if you use to much or don't massage it in completely, but i just love it.\"]\n",
      "\n",
      "\n",
      "124\n",
      "3.56540084388\n",
      "[u\"i don't find it that good.\", u\"i'm about half way through the jar and don't see a lot of difference.i do not have to use anything separate for my eyelids or skin surrounding my eyes.\", u\"i don't see much difference between the products (regenerist and pro-x), but pro-x is much more expensive.although this product leaves your face feeling very silky and smooth, i do not see any change in the appearance of my skin; especially when the product states its a &#34;firming cream&#34;?\", u\"even my children tell i look younger than my friends the same age.this is the best moisturizer i've ever used.save your money.\", u\"for the price you can't go wrong because it works just as well as the expensive creams.\"]\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u'this is the first moisturizer with spf i have found that i love as a moisturizer.', u'it has a medium texture and leaves no residue on the face.', u'i strongly recommend it.']\n",
      "\n",
      "\n",
      "1\n",
      "3.0\n",
      "[u\"it's kind of drying and it leaves marks around your eyes if they even water a little.\", u'you have to make sure you really rub it in, or you will definitely see lines around the nose.', u'my favorite tinted sunscreen moisturizer so far has been aveda.', u'i love the way the aveda makes me look fresh and dewy.', u\"this one makes me feel like i'm putting on old school base.\"]\n",
      "\n",
      "\n",
      "25\n",
      "3.16923076923\n",
      "[u'!i bought this lotion with alpha hydrox enhanced lotion 10 percent glycolic aha 6 oz, mixed them because each of the lotions has ingredients that are good for strech marks.this product has a strong fragrance that may not be acceptable to some people.', u\"not only for older women.once you use retinol on a regular basis, you'll notice a huge difference without it.\", u'this is a must for aging skin.', u\"slightly more expensive than generic, but worth the price.i recently purchased this puritan's choice retinol cream from amazon i am horrified that the product contains so mcuh fragrance i.e.\", u'perfume i have psoraisis and any cream with fragrance causes a serious break out.']\n",
      "\n",
      "\n",
      "8\n",
      "3.12962962963\n",
      "[u'the smell is a little too flowery for my taste but this product feels like a dream.ever since i went to korea i can have enough of korean cosmetics.', u'it smells lightly floral and sinks right into my skin.nature republic proves yet again that most skin care companies are ripping us off.', u\"it's been 5 minutes since application and the scent is still lingering.\", u'it is light and soft feeling on the skin, not heavy; probably not as moisturizing as i was hoping for winter.', u\"i'll do another review after a couple weeks of use.tldr: first impression; container is new favorite, even lovelier than in pic, but no spatula :( lovely womanly floral lingering scent.\"]\n",
      "\n",
      "\n",
      "2\n",
      "3.02941176471\n",
      "[u\"one of the few i've tried that doesn't smell like it contains sunscreen.\", u\"it's tint-free, which i also like.i use it primarily on my face and lower arms where the sun hits.\", u\"a single tube lasts quite awhile.i'm new to this, but so far think it's pretty great.... my dermatologist sells this brand so thought i would try it.\", u'so far so good.', u\"a bit thick and heavy, but that's not a bad thing so i will continue to use it.\"]\n",
      "\n",
      "\n",
      "1\n",
      "2.96078431373\n",
      "[u'this is my first time to order this product hoping and excited to try .', u\"i order this product as per description above quantity 50g (large)  , unfortunately i receive 15 g ( small) try to contact the customer service but i didn't hear from them.\", u'poor service.']\n",
      "\n",
      "\n",
      "22\n",
      "3.224\n",
      "[u\"evelope was slightly opened but product was ok.  no damage inside.i'm so glad to find this on amazon.\", u'with a slogan like \"take me away,\" how could you not love it?each and every time i spritz a bottle of hawaiian ginger, it takes me back to yesterday, the same place people assume calgon should stay (usually those who\\'ve never tried it).', u\"it's trendy enough for teenagers but adult enough for mature women.i recommend that every woman have at least one bottle of calgon hawaiian ginger stashed away in their bathroom.\", u'hope you have it avaiable on my next purchase.', u'they arrived on time & were in great condition.']\n",
      "\n",
      "\n",
      "6\n",
      "3.06542056075\n",
      "[u'i have light skin and am over a certain age ,so the protection is a good thing.i have been using the vip gold and always keep going back to it.', u'the vip gold blends and oxidizes nicely for my fair/beige skin and this purple label bb is just a little too dark.', u\"i have oily skin but somehow this one lasts a long time on my face.this is bar far one of the best bb creams i've ever used.\", u\"i've also noticed an improvement in the overall tone of my skin.i love skin79 bb cream.\", u\"i have some redness, it's not terrible -- but too much underneath concealer looks weird, so i started using bb cream.\"]\n",
      "\n",
      "\n",
      "14\n",
      "3.22807017544\n",
      "[u'my skin looks great!', u'absorbs completely in seconds....i however, use almost a full dropper full rather than the one drop they recommend.', u'i just use sunscreen moisturizer on top of it.', u'!really nice product to compliment your current skin care regime.', u'i have a lot of skin allergies and i find this does not irritate my skin.skin never felt so moist-one drop does entire face-works great as a primer under foundation-even helps plump fine lines!!!']\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u'great product!!!', u\"it's light and non greasy, makes your skin very soft and supple.\", u'i would highly recommend this as a daily moisturizer .']\n",
      "\n",
      "\n",
      "40\n",
      "3.55\n",
      "[u'i liked that this product was organic and that the ingredient list consists of things found in nature.', u'it took about a tablespoon to cover my face so probably once a month would be good for someone like me.', u'after using it for a few weeks, we also noticed that our skin seemsbrighter and clearer.after just one use, we noticed our pores were pretty much gone.', u\"i've personally used organic health supplements in the past and can noticeably tell the difference between organic products verses the imitations.... this product posses the true qualities of a pure organic substance, what i like to call &#34;earthy&#34; quality!\", u'i was very happy with the product and look forward to using it more in the future!first of all, we have never left positive or negative feedback ever never  ever for anything!']\n",
      "\n",
      "\n",
      "23\n",
      "3.06201550388\n",
      "[u'she\\'s especially fond of using it as a hand and leg cream in the winter months to prevent dry skin itching.it\\'s a very traditional cream formulation (i won\\'t call it \"old fashioned\" since i\\'m getting on in years myself!)', u\"one addressed me in english to ask 'how old my son is?'\", u\"it is good for all over not just the face.i call this stuff &#34;granny creme&#34; lol..cuz everyone's granny used this i swear since the dang 50's.\", u'its inexpensive and works great..my mom and grandma used this stuff and they had really young looking skin till they day they both passed.', u'i keep tons of this around and i even use it for my entire body.']\n",
      "\n",
      "\n",
      "0\n",
      "3.0\n",
      "[]\n",
      "\n",
      "\n",
      "7\n",
      "3.06481481481\n",
      "[u'i pretty much accepted the fact that i would always have terrible skin and i would never be able to do anything about it.', u'the products do a wonderful job of keeping my skin moisturized and balanced, but not oily at all.', u'this is the first time in my life that i have ever found products that work for my skin.arbonne is a great skin care line.', u\"i followed the directions on each product carefully to ensure that they would work as intended- this set was a bit more than i was willing to spend and i wanted to make sure i didn't waste the investment!\", u'if that is not an issue for you, you may want to consider skipping that item.']\n",
      "\n",
      "\n",
      "5\n",
      "3.06666666667\n",
      "[u'this is a really nice moisturizer that smells good, too.', u\"i haven't noticed any lightening of dark spots or freckles yet, though.my daughter has experience with pearl cream when it was prescribed by her doctor of chinese medicine.\", u'in addition to acupuncture and chinese herbs, she was told to use pearl cream and no other face lotions or topical acne treatments.', u'i got some for her and i think that i will try it, too.i love it&#65292;thanks!i really like this cream.', u'after a few days of using, i noticed my old acne scars had lightened and my pores looked smaller.']\n",
      "\n",
      "\n",
      "2\n",
      "3.03921568627\n",
      "[u'i am 76 years old and have been using this product for many years.', u'it tightens my sink, keeps it soft and i am never guessed even close to my age.', u\"i'm very pleased to find this on amazon at a good price.i love this lotion and this was a great bargain.it's become hard to find in stores lately,so i was thrilled to get this bargain.\"]\n",
      "\n",
      "\n",
      "15\n",
      "3.07627118644\n",
      "[u'i was shocked to find that when it came, i got the new formula in the new bottle.', u\"can't wait to try it.i purchased this product because i wanted a facial serum similar to perricone's, packed with the same vitamins + supplements, but with a more affordable price.\", u'because it is a bit drying, that makes it a great choice to use in combination with an spf cream.', u'it gives me instant firming, and even makes my little fine lines seem smoothed out.', u'i definitely recommend this to anyone who wants to prevent/treat the signs of aging with a serum full of antioxidants and anti-aging ingredients.']\n",
      "\n",
      "\n",
      "40\n",
      "3.34027777778\n",
      "[u'beware it looks a bit grey going on but it adjusts to your skin tone.i hate buying this product from this seller... because it leaked and made my purse have bb cream all over insidei love this product in general-it matches my skin color and good product to use for skin care.', u\"it gives amazing coverage, and you can't even tell you are wearing anything!\", u\"overall i think it covers well and is worth what you spend on it.my go-to bb cream.i've been using the skin79 gold plus for about 3 years now since i ran out of the oriental gold (used that for 2 years) and then the price raised on the oriental gold so i switched to the gold plus.this clears up my skin and protects me from crazy arizona sun (seriously, the other day, my entire body was burnt except for my face!\", u'bb cream literally becomes like a second skin, which is what i love.', u\"i wish i had read the negative rating before....very light on the skin but covers very well, didn't cause any breakout (given i also have a mia2 by clearsonic) kinda grey on skin.\"]\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u'love it!, my face is definitely smoother, less noticeable lines.', u'overall, more youthful and bright.', u'right price, and i have tried a lot of products!']\n",
      "\n",
      "\n",
      "4\n",
      "3.07692307692\n",
      "[u'i really wish it was available in the states.i absolutely love this hand cream.', u'the sellers made good on their sale when they found out the product had arrived broken, by replacing it free of charge.', u\"almost odorless  and doesn't leave you feeling greasy.\", u\"i will continue to order it from the uk.i've been using this stuff since the 70's.\", u\"there's nothing in the usa that i have found that compares to atrixo and my husband uses it too and said he has never seen anything like it over here.\"]\n",
      "\n",
      "\n",
      "14\n",
      "3.00847457627\n",
      "[u'i use it nightly and it helps to smooth the lines and gives the skin around the eyes an overall smoothness.i have been using elizabeth arden millennium products since released many years ago.', u'however the last tine i ordered it, i received &#34;visible difference&#34; eye cream instead.', u'everything was like inthis was recommended to me years ago when i got a very bad sunburn on my face and actually had burned underneath my eyes.', u'you know eli lillyof indianapolis developed these products.', u\"i don't know it is the right one or defected one.\"]\n",
      "\n",
      "\n",
      "13\n",
      "3.21238938053\n",
      "[u'it is very moisturizing and soothing.also i wanted to let you know that i have made two purchases.', u'the cream arrived in its original packaging: sealed box, instructions and a little spoon.i think that sellers should warn the customers when they are sending unboxed items.', u'some people think this is not the place to review the vendor, but the feedback rating does not help on this matter.', u'i would definitely reoreder it!i have been using this arden miullenium day renewal product for over a month now.', u'go for it gals...non-greasy, lightly scented moisturizer that really helps my aging skin stay supple.']\n",
      "\n",
      "\n",
      "2\n",
      "3.03921568627\n",
      "[u'when applied to my skin~ i feel instantly pampered.', u'it soaks in leaving a nice refreshed feeling.', u'it is a really great product and i would strongly recommend it.love this product.', u'i saw results in about two weeks.', u\"the lines on my forehead improved and at 52 years old, i'll take any improvement!\"]\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u\"i'm 75 years old, it's a very good moisturizing face cream, been using it for years-keeps my skin very soft.\"]\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u'i have used this product for a long time..and i am happy i got it on time.', u'love this product']\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u\"this doesn't claim all the wrinkle benefits of a lot of creams but i don't use anything else when i new moisture.\", u'it leaves my skin so extremely soft and glowing.', u\"i am especially prone to acne and it doesn't make me break out either.\"]\n",
      "\n",
      "\n",
      "117\n",
      "3.36324786325\n",
      "[u\"i am well over fifty and most people that meet me think i am in my 40's.i highly recommend this product.i never have used cream of any sort, but have watched my wife use facial cream to remain beautiful.\", u\"in november '08, i saw they were promoting its starter kit at amazon and i thought i would give it a try - a very last try.................at least.surprisingly, it works!\", u'this also helps in the reduction of wrinkles and i would recommend to anyone that might need help with any wrinklesavg.', u'i would not say it is miraculous with wrinkles, but i like my skins new texture.', u'i got red itchy bumps that i had to stop using it.i have bought this before and loved it.']\n",
      "\n",
      "\n",
      "8\n",
      "3.05504587156\n",
      "[u'too bad, wish i could use it.i gave this product four stars because, the quanity in the container is so little, for the price.', u'i wish i used this product when i was younger, probably would show better results.this product is wonderful for aging skin.', u'apparently the company reserves it for its small boutique vendors, like the one on amazon from whom i purchased it.', u'i purchase it regularly, either from my local vendor or amazon and recommend it to anyone who wants to preserve their aging skin.this stuff works amazingly!', u\"awesome skin again (@42)!i can't hate this one enough.\"]\n",
      "\n",
      "\n",
      "3\n",
      "3.05825242718\n",
      "[u\"this cream is the 'real deal', love  the purity of the product...my daughter-in-law first told me of this product, and i'm glad she did!this stuff is amazing.\", u'i had eczema on my eyes and nothing worked so i ordered this and it not only worked but i no longer had it after using this a few times.i buy this product over and over again from daisy shop.', u'this product works very well with my skin, especially because i have eczema.', u'it is a nice, thick cream that has a natural scent of honey and aloe.', u'it keeps my skin moisturized throughout the night when it tends to get dry.']\n",
      "\n",
      "\n",
      "18\n",
      "3.16666666667\n",
      "[u'he always gets compliments on how young his skin looks.', u\"i've been using this product for quite some time and my skin looks great !\", u'while i was a distributer, (about 15 yrs ago) i used it regularly with great results.', u'people have noticed how soft and beautiful my skin looks.', u'i have not worn any type of make-up during this time, and only wash my face with warm water.']\n",
      "\n",
      "\n",
      "8\n",
      "2.95495495495\n",
      "[u'and, the cream is more like a thick paste.it was not creamy enough for my dry skin, so gave it to husband to use as night cream for his oily skin.', u'have only been using this a few weeks, but i can really see an improvement overall.', u'jar packaging is not ideal.a little bit goes a long way.', u'this creme works amazingly to moisturize without causing breakouts.', u'it was a total waste of money.they made it sound like such an amazing product.']\n",
      "\n",
      "\n",
      "3\n",
      "2.99038461538\n",
      "[u'i love this cream & used it for many years, it makes my skin so soft, & smoothes out wrinkles around my eyes and mouth.', u'a tube lasts forever because you only need a little dime size amount at a time.', u'i was amazed to see someone give it a bad rating, i suggest you try it again maybe you got a bad tube, i think you will be quite surprised at the great results you get.why neutrogena discontinued this product will always astound me!', u'best thing ever made for my complexion!', u\"lower the price, keep it in stock, and you'll have me as a forever client with this particular product!it made my face feel like leather.\"]\n",
      "\n",
      "\n",
      "708\n",
      "3.52192513369\n",
      "[u'i also use the aveeno facial cleansing pads...visibly radiant....and it is well worth every penny!this is a pretty good tinted moisturizer.', u\"i really hate when companies find a lovely product and then just price it higher because they know people love the product so much, they'll spend the money.\", u'will be buying more if it ever shows up on local shelves.one of my favorite cleansers.', u'i have sensitive, combination skin (oily forehead, dry and flaky around nose and mouth) and find it is not too heavy, blends in quickly, spf 30 is great, and it does seem to even skin tone.i made a last minute purchase prior to vacation of the tinted product at a local store as they were out of the non-tinted version.', u'worth a try.i have never used an aveeno product that was not good.']\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u'this cream is amazing!!', u'fine lines disapear  only one problem i believe it is discontinued.', u':(  not sure what to do when it runs out.']\n",
      "\n",
      "\n",
      "15\n",
      "3.18260869565\n",
      "[u\"otherwise, i'll stick with this for a while :)i have been looking for the perfect light moisturizer, one that's not chockful of ingredients with long chemical names.\", u\"if this product isn't perfect, it comes close.\", u\"it helps my skin look more radient.you don't get that much product for the price.\", u\"the iris lotion light and moisturising, doesn't leave any residue, isn't tacky, and absorbs quickly.\", u'i would highly recommend.']\n",
      "\n",
      "\n",
      "13\n",
      "2.90677966102\n",
      "[u'it just looks like lotion with some barely noticeable little brown specks.', u'this one is going back.i bought this product because i have slight acne that tends to get red.', u\"the color was a good match for me, but the correction of  color not so  great, it's just o k ..cannot purchase locally, provides overall coverage and does not feel heavy.\", u\"may be uv factor..?i love loreal's true match concealer - covers everything.since i was so please with itthought i would try this new product.it covers nothingusing the smallest amountit is greasy and shiny.so pleased to know amazon carries loreali did not know they didand i purchase most from them..it's ok, but in summer felt greasy and shinny on my face!\", u\"i have dry areas around my nose and the rest of my facial skin is normal, so i've learned, dab on the nose, and move that around the rest of my face and voila.\"]\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u'this is first time using a cc cream and i love it.', u'i definitely brightens up the skin and adds a glow.', u'my friends kept asking what i did to my skin because it looks nice!', u\"i used bb cream before and i found it to be too heavy and creates the &#34;mask look&#34;.i'm asian and have very dry skin and a little bit of rosacea.\", u'the cc cream is moisturizing and i definitely recommend it.']\n",
      "\n",
      "\n",
      "1\n",
      "2.98039215686\n",
      "[u\"i bought this along with a sampler of dermalogica's anti-aging kit.\", u\"as for the super rich repair, it's an interesting, thick and very moisturising cream.\", u\"sadly i can't use it all around my face (cheeks, nose, chin) because it makes me breakout.\", u\"i've been using it on my forehead to see if it reduces signs of aging (i've got some wrinkles going on there), and seriously, no major results seen.\", u'again, people with oily/combo skin, look else where for products that are oil-free.']\n",
      "\n",
      "\n",
      "172\n",
      "3.85460992908\n",
      "[u'i would recommend it to anyone.i am using too help with  skin condition and it is leaving my skin very soft.', u'i would never be without it again!i chose amlactin because it was recommended by my foot doctor.', u'however, it is well worth every penny and the extra drive.', u\"it burns my skin - wasted my moneyfirst of, i'm 29 years old and always thought i had &#34;acne&#34; on my bum... and used all types of over the counter acne medication and it would never make a difference.\", u'i recommend dry brushing first, then use this.']\n",
      "\n",
      "\n",
      "14\n",
      "3.19298245614\n",
      "[u'its ingredient list include components of moisturizer and emollient.', u'must have and such a good deal from this seller.i have been using this cream for 6 months now and plan to never live without it.my skin is finally well hydrated, radiant.', u'would highly recommend this amazing product.', u\"no matter how much i use, my skin is dry the next morning.this cream, when used together with the total regeneration serum, keeps my skin moisturized overnight,  and it's not heavy or greasy at all.\", u'right on time and i would let others know about it.']\n",
      "\n",
      "\n",
      "101\n",
      "3.4\n",
      "[u'if you use it before getting dressed for the day, you may never get your clothes to fit right.', u'i highly recommend it for lightening age spots and smoothing skin.it might be a good glycolic product, but i had two problems with it.', u'i would recommend and over recommend.', u\"it works so well for me so for those of you who didn't have success using glytone i would recommend trying lactic acid instead.the only draw back is that it is very occlusive.\", u\"it's worth every penny!...\"]\n",
      "\n",
      "\n",
      "1\n",
      "3.0198019802\n",
      "[u'i love this moisturizer.', u'i wear it nightly after washing my face and my face feels so dewy and looks great the next morning.', u\"i have combination skin, but this moisturizer doesn't make me break out and moisturizes in just the right spots.\", u'i love earth science products!']\n",
      "\n",
      "\n",
      "5\n",
      "3.09523809524\n",
      "[u'i wont say it would stay all day but it wont smudge easilyso amazing and lightweight.', u\"the only problem i have with it is the color; it's far too dark for my ghost white skin.\", u\"i'm used to this though, and it was nothing a few pumps of white foundation didn't help with.this bb cream really feels good and doesn't break my acne prone skin out.\", u\"it's light on my medium skin tone so i mix it in with my &#34;it&#34; cc foundation (which is too dark) and it makes a perfect shade and coverage for my face.this bb cream is lightweight and has a good coverage.\", u'it is a little bit dark for my very pale british skin (the skin79 bb cream was lighter), but is still natural looking.']\n",
      "\n",
      "\n",
      "3\n",
      "3.0\n",
      "[u\"derma wand surprisingly gave me a fresh youthful glow it doesn't replace a face look but does sharpen features w out medical enhancement!this is a great product to use while you are using your dermawand, keeps your skin nice and moist so the wand glides nicely over the skin.\", u'the only complaint i have is that the bottle is so small.', u\"but the makes of dermawand say you can use any moisturizer with your wand, which you will end up doing because the bottle is so small.i do like the derma wand, but the preface is small amounts and dries up very quickly, as a gel i substitute watt's peptide serum $18.\", u'and long lasting enough to do your whole face.', u'this pre face product is very expensive considering you use it daily.']\n",
      "\n",
      "\n",
      "5\n",
      "3.01886792453\n",
      "[u'it makes your skin look so healthy and glowing.', u'the slight tint is perfect for evening out skin tone.it really did live up to the hype!i love how it feels when i rub it into my skin.', u'definitely leaves your face feeling fresh and &#34;zing-ed&#34;.', u\"it's a bit more greasy than i would like, but i'm still able to use it.\", u'but psychologically feels nice and smooth and refreshing.']\n",
      "\n",
      "\n",
      "2\n",
      "2.92307692308\n",
      "[u'the first thing i noticed about this cream was the horrible smell.', u'i ignored it and tried rubbing it into my face, but it took forever for the cream to mix in.', u\"it was patchy and white and it wasn't even creamy.\", u\"the package is so cute and deceiving.i had no problem with the sellers, just the product.i give it one star just because i love panda, and the rest because i didn't happy about the delivery date.\", u'it was more than one month.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(50):\n",
    "    item = get_b_product(i)\n",
    "    len_reviews = sum(item['rating'].values())\n",
    "    print len_reviews\n",
    "    print strict_rating(item['rating']['One_star'],\n",
    "                        item['rating']['Two_star'],\n",
    "                        item['rating']['Three_star'],\n",
    "                        item['rating']['Four_star'],\n",
    "                        item['rating']['Five_star'],\n",
    "                        3, 100)\n",
    "    print summarize(item['Reviews'])['top_n_summary']\n",
    "    print \"\"\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far, I found \"sentiment\" to be completely useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.17395833333333335, subjectivity=0.5253540305010894)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb(text[0]).sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Vectorizing a large text corpus with the hashing trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hv = HashingVectorizer(n_features=10)\n",
    "to_matrix = hv.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4004907 ,  0.14303239,  0.4004907 , -0.34327774,  0.        ,\n",
       "        -0.68655548,  0.11442591, -0.05721296, -0.02860648,  0.22885183]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Try ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList([u'Great', u'service', u'my']),\n",
       " WordList([u'service', u'my', u'order']),\n",
       " WordList([u'my', u'order', u'arrived']),\n",
       " WordList([u'order', u'arrived', u'earlier']),\n",
       " WordList([u'arrived', u'earlier', u'than']),\n",
       " WordList([u'earlier', u'than', u'the']),\n",
       " WordList([u'than', u'the', u'expected']),\n",
       " WordList([u'the', u'expected', u'7-10']),\n",
       " WordList([u'expected', u'7-10', u'day']),\n",
       " WordList([u'7-10', u'day', u'shipping']),\n",
       " WordList([u'day', u'shipping', u'through']),\n",
       " WordList([u'shipping', u'through', u'USPS']),\n",
       " WordList([u'through', u'USPS', u'I']),\n",
       " WordList([u'USPS', u'I', u'have']),\n",
       " WordList([u'I', u'have', u'used']),\n",
       " WordList([u'have', u'used', u'this']),\n",
       " WordList([u'used', u'this', u'product']),\n",
       " WordList([u'this', u'product', u'before']),\n",
       " WordList([u'product', u'before', u'and']),\n",
       " WordList([u'before', u'and', u'love']),\n",
       " WordList([u'and', u'love', u'it']),\n",
       " WordList([u'love', u'it', u'I']),\n",
       " WordList([u'it', u'I', u'was']),\n",
       " WordList([u'I', u'was', u'happy']),\n",
       " WordList([u'was', u'happy', u'to']),\n",
       " WordList([u'happy', u'to', u'find']),\n",
       " WordList([u'to', u'find', u'this']),\n",
       " WordList([u'find', u'this', u'great']),\n",
       " WordList([u'this', u'great', u'deal']),\n",
       " WordList([u'great', u'deal', u'through']),\n",
       " WordList([u'deal', u'through', u'Amazon']),\n",
       " WordList([u'through', u'Amazon', u'I']),\n",
       " WordList([u'Amazon', u'I', u'ordered']),\n",
       " WordList([u'I', u'ordered', u'two']),\n",
       " WordList([u'ordered', u'two', u'of']),\n",
       " WordList([u'two', u'of', u'these']),\n",
       " WordList([u'of', u'these', u'moisturizers']),\n",
       " WordList([u'these', u'moisturizers', u'and']),\n",
       " WordList([u'moisturizers', u'and', u'the']),\n",
       " WordList([u'and', u'the', u'Decleor']),\n",
       " WordList([u'the', u'Decleor', u'boxes']),\n",
       " WordList([u'Decleor', u'boxes', u'that']),\n",
       " WordList([u'boxes', u'that', u'the']),\n",
       " WordList([u'that', u'the', u'moisturizers']),\n",
       " WordList([u'the', u'moisturizers', u'came']),\n",
       " WordList([u'moisturizers', u'came', u'in']),\n",
       " WordList([u'came', u'in', u'were']),\n",
       " WordList([u'in', u'were', u'a']),\n",
       " WordList([u'were', u'a', u'little']),\n",
       " WordList([u'a', u'little', u'dinged']),\n",
       " WordList([u'little', u'dinged', u'up']),\n",
       " WordList([u'dinged', u'up', u'after']),\n",
       " WordList([u'up', u'after', u'making']),\n",
       " WordList([u'after', u'making', u'their']),\n",
       " WordList([u'making', u'their', u'way']),\n",
       " WordList([u'their', u'way', u'through']),\n",
       " WordList([u'way', u'through', u'US']),\n",
       " WordList([u'through', u'US', u'mail']),\n",
       " WordList([u'US', u'mail', u'but']),\n",
       " WordList([u'mail', u'but', u'the']),\n",
       " WordList([u'but', u'the', u'jars']),\n",
       " WordList([u'the', u'jars', u'inside']),\n",
       " WordList([u'jars', u'inside', u'were']),\n",
       " WordList([u'inside', u'were', u'not']),\n",
       " WordList([u'were', u'not', u'damaged']),\n",
       " WordList([u'not', u'damaged', u'at']),\n",
       " WordList([u'damaged', u'at', u'all']),\n",
       " WordList([u'at', u'all', u'so']),\n",
       " WordList([u'all', u'so', u'I']),\n",
       " WordList([u'so', u'I', u'have']),\n",
       " WordList([u'I', u'have', u'no']),\n",
       " WordList([u'have', u'no', u'complaints']),\n",
       " WordList([u'no', u'complaints', u'Would']),\n",
       " WordList([u'complaints', u'Would', u'recommend']),\n",
       " WordList([u'Would', u'recommend', u'this']),\n",
       " WordList([u'recommend', u'this', u'seller']),\n",
       " WordList([u'this', u'seller', u'The']),\n",
       " WordList([u'seller', u'The', u'pros']),\n",
       " WordList([u'The', u'pros', u'You']),\n",
       " WordList([u'pros', u'You', u'use']),\n",
       " WordList([u'You', u'use', u'a']),\n",
       " WordList([u'use', u'a', u'very']),\n",
       " WordList([u'a', u'very', u'tiny']),\n",
       " WordList([u'very', u'tiny', u'little']),\n",
       " WordList([u'tiny', u'little', u'bit']),\n",
       " WordList([u'little', u'bit', u'and']),\n",
       " WordList([u'bit', u'and', u'it']),\n",
       " WordList([u'and', u'it', u'goes']),\n",
       " WordList([u'it', u'goes', u'a']),\n",
       " WordList([u'goes', u'a', u'long']),\n",
       " WordList([u'a', u'long', u'way']),\n",
       " WordList([u'long', u'way', u'Feels']),\n",
       " WordList([u'way', u'Feels', u'very']),\n",
       " WordList([u'Feels', u'very', u'non-greasy']),\n",
       " WordList([u'very', u'non-greasy', u'but']),\n",
       " WordList([u'non-greasy', u'but', u'still']),\n",
       " WordList([u'but', u'still', u'quenches']),\n",
       " WordList([u'still', u'quenches', u'my']),\n",
       " WordList([u'quenches', u'my', u'skin']),\n",
       " WordList([u'my', u'skin', u\"'s\"]),\n",
       " WordList([u'skin', u\"'s\", u'thirst.The']),\n",
       " WordList([u\"'s\", u'thirst.The', u'con']),\n",
       " WordList([u'thirst.The', u'con', u'Price']),\n",
       " WordList([u'con', u'Price', u'Although']),\n",
       " WordList([u'Price', u'Although', u'obviously']),\n",
       " WordList([u'Although', u'obviously', u'you']),\n",
       " WordList([u'obviously', u'you', u'could']),\n",
       " WordList([u'you', u'could', u'do']),\n",
       " WordList([u'could', u'do', u'worse']),\n",
       " WordList([u'do', u'worse', u'this']),\n",
       " WordList([u'worse', u'this', u'does']),\n",
       " WordList([u'this', u'does', u'cost']),\n",
       " WordList([u'does', u'cost', u'more']),\n",
       " WordList([u'cost', u'more', u'than']),\n",
       " WordList([u'more', u'than', u'other']),\n",
       " WordList([u'than', u'other', u'brands.All']),\n",
       " WordList([u'other', u'brands.All', u'in']),\n",
       " WordList([u'brands.All', u'in', u'all']),\n",
       " WordList([u'in', u'all', u'I']),\n",
       " WordList([u'all', u'I', u'love']),\n",
       " WordList([u'I', u'love', u'this']),\n",
       " WordList([u'love', u'this', u'moisturizer']),\n",
       " WordList([u'this', u'moisturizer', u'and']),\n",
       " WordList([u'moisturizer', u'and', u'have']),\n",
       " WordList([u'and', u'have', u'been']),\n",
       " WordList([u'have', u'been', u'using']),\n",
       " WordList([u'been', u'using', u'it']),\n",
       " WordList([u'using', u'it', u'for']),\n",
       " WordList([u'it', u'for', u'years']),\n",
       " WordList([u'for', u'years', u'I']),\n",
       " WordList([u'years', u'I', u\"'m\"]),\n",
       " WordList([u'I', u\"'m\", u'fussy']),\n",
       " WordList([u\"'m\", u'fussy', u'about']),\n",
       " WordList([u'fussy', u'about', u'what']),\n",
       " WordList([u'about', u'what', u'I']),\n",
       " WordList([u'what', u'I', u'put']),\n",
       " WordList([u'I', u'put', u'on']),\n",
       " WordList([u'put', u'on', u'my']),\n",
       " WordList([u'on', u'my', u'47']),\n",
       " WordList([u'my', u'47', u'year']),\n",
       " WordList([u'47', u'year', u'old']),\n",
       " WordList([u'year', u'old', u'face']),\n",
       " WordList([u'old', u'face', u'these']),\n",
       " WordList([u'face', u'these', u'days']),\n",
       " WordList([u'these', u'days', u'Luckily']),\n",
       " WordList([u'days', u'Luckily', u'good']),\n",
       " WordList([u'Luckily', u'good', u'family']),\n",
       " WordList([u'good', u'family', u'genes']),\n",
       " WordList([u'family', u'genes', u'help']),\n",
       " WordList([u'genes', u'help', u'me']),\n",
       " WordList([u'help', u'me', u'to']),\n",
       " WordList([u'me', u'to', u'look']),\n",
       " WordList([u'to', u'look', u'younger']),\n",
       " WordList([u'look', u'younger', u'than']),\n",
       " WordList([u'younger', u'than', u'my']),\n",
       " WordList([u'than', u'my', u'years']),\n",
       " WordList([u'my', u'years', u'but']),\n",
       " WordList([u'years', u'but', u'I']),\n",
       " WordList([u'but', u'I', u'still']),\n",
       " WordList([u'I', u'still', u'moisturize']),\n",
       " WordList([u'still', u'moisturize', u'and']),\n",
       " WordList([u'moisturize', u'and', u'use']),\n",
       " WordList([u'and', u'use', u'sun']),\n",
       " WordList([u'use', u'sun', u'screen']),\n",
       " WordList([u'sun', u'screen', u'Being']),\n",
       " WordList([u'screen', u'Being', u'older']),\n",
       " WordList([u'Being', u'older', u'and']),\n",
       " WordList([u'older', u'and', u'wiser']),\n",
       " WordList([u'and', u'wiser', u'helps']),\n",
       " WordList([u'wiser', u'helps', u'me']),\n",
       " WordList([u'helps', u'me', u'not']),\n",
       " WordList([u'me', u'not', u'to']),\n",
       " WordList([u'not', u'to', u'foolishly']),\n",
       " WordList([u'to', u'foolishly', u'spend']),\n",
       " WordList([u'foolishly', u'spend', u'on']),\n",
       " WordList([u'spend', u'on', u'face']),\n",
       " WordList([u'on', u'face', u'cream']),\n",
       " WordList([u'face', u'cream', u'I']),\n",
       " WordList([u'cream', u'I', u'do']),\n",
       " WordList([u'I', u'do', u\"n't\"]),\n",
       " WordList([u'do', u\"n't\", u'need']),\n",
       " WordList([u\"n't\", u'need', u'or']),\n",
       " WordList([u'need', u'or', u'use']),\n",
       " WordList([u'or', u'use', u'5']),\n",
       " WordList([u'use', u'5', u'different']),\n",
       " WordList([u'5', u'different', u'ones']),\n",
       " WordList([u'different', u'ones', u'or']),\n",
       " WordList([u'ones', u'or', u'one']),\n",
       " WordList([u'or', u'one', u'for']),\n",
       " WordList([u'one', u'for', u'every']),\n",
       " WordList([u'for', u'every', u'problem']),\n",
       " WordList([u'every', u'problem', u'But']),\n",
       " WordList([u'problem', u'But', u'this']),\n",
       " WordList([u'But', u'this', u'Hydra']),\n",
       " WordList([u'this', u'Hydra', u'Floral']),\n",
       " WordList([u'Hydra', u'Floral', u'cream']),\n",
       " WordList([u'Floral', u'cream', u'is']),\n",
       " WordList([u'cream', u'is', u'the']),\n",
       " WordList([u'is', u'the', u'best']),\n",
       " WordList([u'the', u'best', u'for']),\n",
       " WordList([u'best', u'for', u'me']),\n",
       " WordList([u'for', u'me', u'Love']),\n",
       " WordList([u'me', u'Love', u'the']),\n",
       " WordList([u'Love', u'the', u'scent']),\n",
       " WordList([u'the', u'scent', u'and']),\n",
       " WordList([u'scent', u'and', u'best']),\n",
       " WordList([u'and', u'best', u'of']),\n",
       " WordList([u'best', u'of', u'all']),\n",
       " WordList([u'of', u'all', u'it']),\n",
       " WordList([u'all', u'it', u\"'s\"]),\n",
       " WordList([u'it', u\"'s\", u'effective']),\n",
       " WordList([u\"'s\", u'effective', u'and']),\n",
       " WordList([u'effective', u'and', u'a']),\n",
       " WordList([u'and', u'a', u'little']),\n",
       " WordList([u'a', u'little', u'goes']),\n",
       " WordList([u'little', u'goes', u'a']),\n",
       " WordList([u'goes', u'a', u'long']),\n",
       " WordList([u'a', u'long', u'way']),\n",
       " WordList([u'long', u'way', u'A']),\n",
       " WordList([u'way', u'A', u'1.7oz']),\n",
       " WordList([u'A', u'1.7oz', u'jar']),\n",
       " WordList([u'1.7oz', u'jar', u'can']),\n",
       " WordList([u'jar', u'can', u'last']),\n",
       " WordList([u'can', u'last', u'me']),\n",
       " WordList([u'last', u'me', u'a']),\n",
       " WordList([u'me', u'a', u'year']),\n",
       " WordList([u'a', u'year', u'I']),\n",
       " WordList([u'year', u'I', u'ordered']),\n",
       " WordList([u'I', u'ordered', u'last']),\n",
       " WordList([u'ordered', u'last', u'time']),\n",
       " WordList([u'last', u'time', u'from']),\n",
       " WordList([u'time', u'from', u'123Skincare']),\n",
       " WordList([u'from', u'123Skincare', u'and']),\n",
       " WordList([u'123Skincare', u'and', u'I']),\n",
       " WordList([u'and', u'I', u'promised']),\n",
       " WordList([u'I', u'promised', u'to']),\n",
       " WordList([u'promised', u'to', u'give']),\n",
       " WordList([u'to', u'give', u'them']),\n",
       " WordList([u'give', u'them', u'a']),\n",
       " WordList([u'them', u'a', u'good']),\n",
       " WordList([u'a', u'good', u'review']),\n",
       " WordList([u'good', u'review', u'after']),\n",
       " WordList([u'review', u'after', u'a']),\n",
       " WordList([u'after', u'a', u'bumpy']),\n",
       " WordList([u'a', u'bumpy', u'start']),\n",
       " WordList([u'bumpy', u'start', u'to']),\n",
       " WordList([u'start', u'to', u'my']),\n",
       " WordList([u'to', u'my', u'order']),\n",
       " WordList([u'my', u'order', u'that']),\n",
       " WordList([u'order', u'that', u'they']),\n",
       " WordList([u'that', u'they', u'quickly']),\n",
       " WordList([u'they', u'quickly', u'replied']),\n",
       " WordList([u'quickly', u'replied', u'to']),\n",
       " WordList([u'replied', u'to', u'They']),\n",
       " WordList([u'to', u'They', u'were']),\n",
       " WordList([u'They', u'were', u'very']),\n",
       " WordList([u'were', u'very', u'interested']),\n",
       " WordList([u'very', u'interested', u'in']),\n",
       " WordList([u'interested', u'in', u'me']),\n",
       " WordList([u'in', u'me', u'being']),\n",
       " WordList([u'me', u'being', u'happy']),\n",
       " WordList([u'being', u'happy', u'and']),\n",
       " WordList([u'happy', u'and', u'because']),\n",
       " WordList([u'and', u'because', u'of']),\n",
       " WordList([u'because', u'of', u'that']),\n",
       " WordList([u'of', u'that', u'I']),\n",
       " WordList([u'that', u'I', u'will']),\n",
       " WordList([u'I', u'will', u'order']),\n",
       " WordList([u'will', u'order', u'from']),\n",
       " WordList([u'order', u'from', u'them']),\n",
       " WordList([u'from', u'them', u'again']),\n",
       " WordList([u'them', u'again', u'This']),\n",
       " WordList([u'again', u'This', u'cream']),\n",
       " WordList([u'This', u'cream', u'is']),\n",
       " WordList([u'cream', u'is', u'such']),\n",
       " WordList([u'is', u'such', u'a']),\n",
       " WordList([u'such', u'a', u'total']),\n",
       " WordList([u'a', u'total', u'waste']),\n",
       " WordList([u'total', u'waste', u'of']),\n",
       " WordList([u'waste', u'of', u'money']),\n",
       " WordList([u'of', u'money', u'Your']),\n",
       " WordList([u'money', u'Your', u'better']),\n",
       " WordList([u'Your', u'better', u'off']),\n",
       " WordList([u'better', u'off', u'at']),\n",
       " WordList([u'off', u'at', u'the']),\n",
       " WordList([u'at', u'the', u'drug']),\n",
       " WordList([u'the', u'drug', u'store']),\n",
       " WordList([u'drug', u'store', u'Sad']),\n",
       " WordList([u'store', u'Sad', u'but']),\n",
       " WordList([u'Sad', u'but', u'true']),\n",
       " WordList([u'but', u'true', u'labeling']),\n",
       " WordList([u'true', u'labeling', u'is']),\n",
       " WordList([u'labeling', u'is', u'such']),\n",
       " WordList([u'is', u'such', u'a']),\n",
       " WordList([u'such', u'a', u'market']),\n",
       " WordList([u'a', u'market', u'strategy']),\n",
       " WordList([u'market', u'strategy', u'I']),\n",
       " WordList([u'strategy', u'I', u'would']),\n",
       " WordList([u'I', u'would', u'give']),\n",
       " WordList([u'would', u'give', u'this']),\n",
       " WordList([u'give', u'this', u'0']),\n",
       " WordList([u'this', u'0', u'stars']),\n",
       " WordList([u'0', u'stars', u'if']),\n",
       " WordList([u'stars', u'if', u'I']),\n",
       " WordList([u'if', u'I', u'could']),\n",
       " WordList([u'I', u'could', u'because']),\n",
       " WordList([u'could', u'because', u'I']),\n",
       " WordList([u'because', u'I', u'ordered']),\n",
       " WordList([u'I', u'ordered', u\"'Hydra\"]),\n",
       " WordList([u'ordered', u\"'Hydra\", u'Floral']),\n",
       " WordList([u\"'Hydra\", u'Floral', u'Anti-Pollution']),\n",
       " WordList([u'Floral', u'Anti-Pollution', u'34']),\n",
       " WordList([u'Anti-Pollution', u'34', u'but']),\n",
       " WordList([u'34', u'but', u'I']),\n",
       " WordList([u'but', u'I', u'received']),\n",
       " WordList([u'I', u'received', u'the']),\n",
       " WordList([u'received', u'the', u'34']),\n",
       " WordList([u'the', u'34', u'Hydra']),\n",
       " WordList([u'34', u'Hydra', u'Floral']),\n",
       " WordList([u'Hydra', u'Floral', u'Multi-Protection']),\n",
       " WordList([u'Floral', u'Multi-Protection', u'34']),\n",
       " WordList([u'Multi-Protection', u'34', u'face']),\n",
       " WordList([u'34', u'face', u'creme']),\n",
       " WordList([u'face', u'creme', u'which']),\n",
       " WordList([u'creme', u'which', u'is']),\n",
       " WordList([u'which', u'is', u'much']),\n",
       " WordList([u'is', u'much', u'thicker']),\n",
       " WordList([u'much', u'thicker', u'and']),\n",
       " WordList([u'thicker', u'and', u'has']),\n",
       " WordList([u'and', u'has', u'a']),\n",
       " WordList([u'has', u'a', u'completely']),\n",
       " WordList([u'a', u'completely', u'different']),\n",
       " WordList([u'completely', u'different', u'scent']),\n",
       " WordList([u'different', u'scent', u'It']),\n",
       " WordList([u'scent', u'It', u'also']),\n",
       " WordList([u'It', u'also', u'does']),\n",
       " WordList([u'also', u'does', u'not']),\n",
       " WordList([u'does', u'not', u'moisturize']),\n",
       " WordList([u'not', u'moisturize', u'my']),\n",
       " WordList([u'moisturize', u'my', u'face']),\n",
       " WordList([u'my', u'face', u'as']),\n",
       " WordList([u'face', u'as', u'well']),\n",
       " WordList([u'as', u'well', u'despite']),\n",
       " WordList([u'well', u'despite', u'being']),\n",
       " WordList([u'despite', u'being', u'thicker.I']),\n",
       " WordList([u'being', u'thicker.I', u'absolutely']),\n",
       " WordList([u'thicker.I', u'absolutely', u'love']),\n",
       " WordList([u'absolutely', u'love', u'the']),\n",
       " WordList([u'love', u'the', u'Hydra']),\n",
       " WordList([u'the', u'Hydra', u'Floral']),\n",
       " WordList([u'Hydra', u'Floral', u'face']),\n",
       " WordList([u'Floral', u'face', u'creme']),\n",
       " WordList([u'face', u'creme', u'and']),\n",
       " WordList([u'creme', u'and', u'have']),\n",
       " WordList([u'and', u'have', u'been']),\n",
       " WordList([u'have', u'been', u'using']),\n",
       " WordList([u'been', u'using', u'it']),\n",
       " WordList([u'using', u'it', u'for']),\n",
       " WordList([u'it', u'for', u'years']),\n",
       " WordList([u'for', u'years', u'and']),\n",
       " WordList([u'years', u'and', u'have']),\n",
       " WordList([u'and', u'have', u'even']),\n",
       " WordList([u'have', u'even', u'ordered']),\n",
       " WordList([u'even', u'ordered', u'it']),\n",
       " WordList([u'ordered', u'it', u'from']),\n",
       " WordList([u'it', u'from', u'Amazon']),\n",
       " WordList([u'from', u'Amazon', u'before']),\n",
       " WordList([u'Amazon', u'before', u'without']),\n",
       " WordList([u'before', u'without', u'issue']),\n",
       " WordList([u'without', u'issue', u'so']),\n",
       " WordList([u'issue', u'so', u'imagine']),\n",
       " WordList([u'so', u'imagine', u'my']),\n",
       " WordList([u'imagine', u'my', u'shock']),\n",
       " WordList([u'my', u'shock', u'and']),\n",
       " WordList([u'shock', u'and', u'disappointment']),\n",
       " WordList([u'and', u'disappointment', u'when']),\n",
       " WordList([u'disappointment', u'when', u'I']),\n",
       " WordList([u'when', u'I', u'received']),\n",
       " WordList([u'I', u'received', u'the']),\n",
       " WordList([u'received', u'the', u'wrong']),\n",
       " WordList([u'the', u'wrong', u'face']),\n",
       " WordList([u'wrong', u'face', u'creme']),\n",
       " WordList([u'face', u'creme', u'and']),\n",
       " WordList([u'creme', u'and', u'then']),\n",
       " WordList([u'and', u'then', u'found']),\n",
       " WordList([u'then', u'found', u'that']),\n",
       " WordList([u'found', u'that', u'Amazon']),\n",
       " WordList([u'that', u'Amazon', u'does']),\n",
       " WordList([u'Amazon', u'does', u'not']),\n",
       " WordList([u'does', u'not', u'allow']),\n",
       " WordList([u'not', u'allow', u'this']),\n",
       " WordList([u'allow', u'this', u'type']),\n",
       " WordList([u'this', u'type', u'of']),\n",
       " WordList([u'type', u'of', u'product']),\n",
       " WordList([u'of', u'product', u'to']),\n",
       " WordList([u'product', u'to', u'be']),\n",
       " WordList([u'to', u'be', u'returned']),\n",
       " WordList([u'be', u'returned', u'I']),\n",
       " WordList([u'returned', u'I', u'understand']),\n",
       " WordList([u'I', u'understand', u'that']),\n",
       " WordList([u'understand', u'that', u'the']),\n",
       " WordList([u'that', u'the', u'small']),\n",
       " WordList([u'the', u'small', u'print']),\n",
       " WordList([u'small', u'print', u'of']),\n",
       " WordList([u'print', u'of', u'the']),\n",
       " WordList([u'of', u'the', u'product']),\n",
       " WordList([u'the', u'product', u'description']),\n",
       " WordList([u'product', u'description', u'says']),\n",
       " WordList([u'description', u'says', u'34']),\n",
       " WordList([u'says', u'34', u'Due']),\n",
       " WordList([u'34', u'Due', u'to']),\n",
       " WordList([u'Due', u'to', u'a']),\n",
       " WordList([u'to', u'a', u'manufacturer']),\n",
       " WordList([u'a', u'manufacturer', u'packaging']),\n",
       " WordList([u'manufacturer', u'packaging', u'change']),\n",
       " WordList([u'packaging', u'change', u'item']),\n",
       " WordList([u'change', u'item', u'received']),\n",
       " WordList([u'item', u'received', u'may']),\n",
       " WordList([u'received', u'may', u'vary']),\n",
       " WordList([u'may', u'vary', u'from']),\n",
       " WordList([u'vary', u'from', u'photograph']),\n",
       " WordList([u'from', u'photograph', u'34']),\n",
       " WordList([u'photograph', u'34', u'but']),\n",
       " WordList([u'34', u'but', u'IMO']),\n",
       " WordList([u'but', u'IMO', u'that']),\n",
       " WordList([u'IMO', u'that', u'should']),\n",
       " WordList([u'that', u'should', u'not']),\n",
       " WordList([u'should', u'not', u'mean']),\n",
       " WordList([u'not', u'mean', u'that']),\n",
       " WordList([u'mean', u'that', u'they']),\n",
       " WordList([u'that', u'they', u'can']),\n",
       " WordList([u'they', u'can', u'send']),\n",
       " WordList([u'can', u'send', u'you']),\n",
       " WordList([u'send', u'you', u'a']),\n",
       " WordList([u'you', u'a', u'completely']),\n",
       " WordList([u'a', u'completely', u'different']),\n",
       " WordList([u'completely', u'different', u'product']),\n",
       " WordList([u'different', u'product', u'than']),\n",
       " WordList([u'product', u'than', u'the']),\n",
       " WordList([u'than', u'the', u'one']),\n",
       " WordList([u'the', u'one', u'advertised']),\n",
       " WordList([u'one', u'advertised', u'and']),\n",
       " WordList([u'advertised', u'and', u'ordered']),\n",
       " WordList([u'and', u'ordered', u'A']),\n",
       " WordList([u'ordered', u'A', u'different']),\n",
       " WordList([u'A', u'different', u'box']),\n",
       " WordList([u'different', u'box', u'or']),\n",
       " WordList([u'box', u'or', u'jar']),\n",
       " WordList([u'or', u'jar', u'sure']),\n",
       " WordList([u'jar', u'sure', u'but']),\n",
       " WordList([u'sure', u'but', u'not']),\n",
       " WordList([u'but', u'not', u'a']),\n",
       " WordList([u'not', u'a', u'completely']),\n",
       " WordList([u'a', u'completely', u'DIFFERENT']),\n",
       " WordList([u'completely', u'DIFFERENT', u'item']),\n",
       " WordList([u'DIFFERENT', u'item', u'Very']),\n",
       " WordList([u'item', u'Very', u'disappointed']),\n",
       " WordList([u'Very', u'disappointed', u'and']),\n",
       " WordList([u'disappointed', u'and', u'wo']),\n",
       " WordList([u'and', u'wo', u\"n't\"]),\n",
       " WordList([u'wo', u\"n't\", u'be']),\n",
       " WordList([u\"n't\", u'be', u'ordering']),\n",
       " WordList([u'be', u'ordering', u'this']),\n",
       " WordList([u'ordering', u'this', u'from']),\n",
       " WordList([u'this', u'from', u'Amazon']),\n",
       " WordList([u'from', u'Amazon', u'again'])]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = tb(text[0])\n",
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###We can see that document summarization provides much more informations that are important about a product\n",
    "\n",
    "####For now, (in my opinion), mean score summary provided better summary of review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def amazon_rating(x1,x2,x3,x4,x5):\n",
    "    return (x1+2*x2+3*x3+4*x4+5*x5)/float(x1+x2+x3+x4+x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 shades rating 3.47656102918\n",
      "twightlight rating 4.12725696952\n",
      "the hobbit rating 4.69792682927\n",
      "daughter of the forest 4.47708333333\n",
      "best seller of 2014 4.41966048164\n",
      "divergent 4.52524465651\n",
      "eragon 3.95181718062\n",
      "to kill a mocking bird 4.67559626685\n"
     ]
    }
   ],
   "source": [
    "print \"50 shades rating\", amazon_rating(7708,2732,2970,3584,14876)\n",
    "print \"twightlight rating\", amazon_rating(802,349,503,781,4488)\n",
    "print \"the hobbit rating\", amazon_rating(141,104,265,1071,6619)\n",
    "print \"daughter of the forest\", amazon_rating(20,20,19,73,348)\n",
    "print \"best seller of 2014\", amazon_rating(100,108,166,414,1745)\n",
    "print \"divergent\", amazon_rating(411,519,1316,3918,14375)\n",
    "print \"eragon\", amazon_rating(443,267,331,572,2019)\n",
    "print \"to kill a mocking bird\", amazon_rating(141,96,184,657,4708)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_rating(x1,x2,x3,x4,x5,alpha,beta):\n",
    "    return ((x1+2*x2+3*x3+4*x4+5*x5)+alpha*beta)/(float(x1+x2+x3+x4+x5)+beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 shades rating 3.47507037848\n",
      "twightlight rating 4.11120603731\n",
      "the hobbit rating 4.67746987952\n",
      "daughter of the forest 4.2224137931\n",
      "best seller of 2014 4.36574249905\n",
      "divergent 4.51785454722\n",
      "eragon 3.92631296892\n",
      "to kill a mocking bird 4.64712878016\n"
     ]
    }
   ],
   "source": [
    "print \"50 shades rating\", smooth_rating(7708,2732,2970,3584,14876,3,100)\n",
    "print \"twightlight rating\", smooth_rating(802,349,503,781,4488,3,100)\n",
    "print \"the hobbit rating\", smooth_rating(141,104,265,1071,6619,3,100)\n",
    "print \"daughter of the forest\", smooth_rating(20,20,19,73,348,3,100)\n",
    "print \"best seller of 2014\", smooth_rating(100,108,166,414,1745,3,100)\n",
    "print \"divergent\", smooth_rating(411,519,1316,3918,14375,3,100)\n",
    "print \"eragon\", smooth_rating(443,267,331,572,2019,3,100)\n",
    "print \"to kill a mocking bird\", smooth_rating(141,96,184,657,4708,3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_extreme_rating(x1,x2,x3,x4,x5,alpha,beta):\n",
    "    numer = (2*x1+2*x2+3*x3+4*x4+10*x5)+alpha*beta\n",
    "    denom = float(2*x1+x2+x3+x4+2*x5+beta)\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 shades rating 3.54118854713\n",
      "twightlight rating 4.23251847641\n",
      "the hobbit rating 4.78479415671\n",
      "daughter of the forest 4.43987341772\n",
      "best seller of 2014 4.53774006253\n",
      "divergent 4.67268877911\n",
      "eragon 4.06700032289\n",
      "to kill a mocking bird 4.75398230088\n"
     ]
    }
   ],
   "source": [
    "print \"50 shades rating\", weight_extreme_rating(7708,2732,2970,3584,14876,3,100)\n",
    "print \"twightlight rating\", weight_extreme_rating(802,349,503,781,4488,3,100)\n",
    "print \"the hobbit rating\", weight_extreme_rating(141,104,265,1071,6619,3,100)\n",
    "print \"daughter of the forest\", weight_extreme_rating(20,20,19,73,348,3,100)\n",
    "print \"best seller of 2014\", weight_extreme_rating(100,108,166,414,1745,3,100)\n",
    "print \"divergent\", weight_extreme_rating(411,519,1316,3918,14375,3,100)\n",
    "print \"eragon\", weight_extreme_rating(443,267,331,572,2019,3,100)\n",
    "print \"to kill a mocking bird\", weight_extreme_rating(141,96,184,657,4708,3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Strict rating weight one-star and two-star reviews twice\n",
    "#as heavy as the other reviews. \n",
    "#This rating method is based on common sense way of people when \n",
    "#choosing a product (they care more about flaw of the products than all the good points)\n",
    "def strict_rating(x1,x2,x3,x4,x5,alpha,beta):\n",
    "    numer = (2*x1+4*x2+3*x3+4*x4+5*x5)+alpha*beta\n",
    "    denom = float(2*x1+2*x2+x3+x4+x5+beta)\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 shades rating 2.9302051403\n",
      "twightlight rating 3.71580621483\n",
      "the hobbit rating 4.5842012873\n",
      "daughter of the forest 4.04677419355\n",
      "best seller of 2014 4.15733896515\n",
      "divergent 4.39023598683\n",
      "eragon 3.5186852769\n",
      "to kill a mocking bird 4.52163971909\n"
     ]
    }
   ],
   "source": [
    "print \"50 shades rating\", strict_rating(7708,2732,2970,3584,14876,3,100)\n",
    "print \"twightlight rating\", strict_rating(802,349,503,781,4488,3,100)\n",
    "print \"the hobbit rating\", strict_rating(141,104,265,1071,6619,3,100)\n",
    "print \"daughter of the forest\", strict_rating(20,20,19,73,348,3,100)\n",
    "print \"best seller of 2014\", strict_rating(100,108,166,414,1745,3,100)\n",
    "print \"divergent\", strict_rating(411,519,1316,3918,14375,3,100)\n",
    "print \"eragon\", strict_rating(443,267,331,572,2019,3,100)\n",
    "print \"to kill a mocking bird\", strict_rating(141,96,184,657,4708,3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.06906906907\n",
      "3.77725118483\n",
      "4.19783197832\n",
      "3.52302631579\n",
      "3.42258748674\n"
     ]
    }
   ],
   "source": [
    "print strict_rating(1,0,3,32,193,2.5,100)\n",
    "print strict_rating(0,0,1,6,104,2.5,100)\n",
    "print strict_rating(0,1,7,31,230,2.5,100)\n",
    "print strict_rating(253,184,297,590,2428,2.5,100)\n",
    "print strict_rating(101,64,117,205,895,2.5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strict_rating(x1,x2,x3,x4,x5,alpha,beta):\n",
    "    numer = (3*x1+4*x2+3*x3+4*x4+5*x5)+alpha*beta\n",
    "    denom = float(5*x1+x2+x3+x4+x5+beta)\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.stem.snowball.SnowballStemmer at 0x1176bd410>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
