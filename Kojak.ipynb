{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from bson.son import SON\n",
    "from bson.code import Code\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "# These are packages need for natural language processing:\n",
    "import nltk\n",
    "from __future__ import division, unicode_literals \n",
    "from textblob import TextBlob as tb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "#creating mbf database (mbf = \"meta beauty file\")\n",
    "mbf = client.dsbc.mbf\n",
    "# mbf.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('meta_Beauty.json') as meta_beauty_file:\n",
    "    for line in meta_beauty_file:\n",
    "        meta_f = json.loads(line)  \n",
    "        #only work when using json.loads() not json.load() \n",
    "        mbf.insert(meta_f)\n",
    "        \n",
    "#can't do json.load(meta_beautfy_file) since meta_beauty_file has the form \"{...}{...}{...}\" --> not json\n",
    "#json.load(line) does not work since line is  string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"categories\": [[\"Beauty\", \"Skin Care\",...]] --> need to $unwind\n",
    "# use \"categories.0\" get the innner list.\n",
    "\n",
    "#Skin_care = mbf.find({\"categories.0\": [\"Beauty\"]})\n",
    "\n",
    "pipeline  = [{\"$unwind\":\"$categories\"},\n",
    "             {\"$match\":{\"categories\":{\"$all\":[\"Face\",\"Creams & Moisturizers\"]}}},\n",
    "             {\"$project\":{\"_id\":0,\"asin\":1,\"title\":1,\"price\":1}},\n",
    "             {\"$out\": \"product_info\"}]\n",
    "# \"$out\" write the result into new collection\n",
    "# \"$all\" find all list that contains everything in queries\n",
    "mbf.aggregate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_info = client.dsbc.product_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# name = product_info.find({}, {\"_id\":0,\"asin\":1})\n",
    "# id_list  = {}\n",
    "# for id_num in name:\n",
    "#     id_list.append(id_num[\"asin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = product_info.find({}, {\"_id\":0,\"asin\":1,\"title\":1,\"price\":1})\n",
    "id_list  = {}\n",
    "for id_num in name:\n",
    "    try:\n",
    "        id_list[id_num[\"asin\"]]=[id_num[\"title\"],id_num[\"price\"]]\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#id_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating database for reviews beauty file\n",
    "rbf = client.dsbc.rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('reviews_Beauty.json') as reviews_beauty_file:\n",
    "    for line in reviews_beauty_file:\n",
    "        review = json.loads(line)  \n",
    "        rbf.insert(review)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new database for selective items\n",
    "ndb = client.dsbc.ndb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beauty_item_info = {id_list.keys()[0] : id_list.values()[0], \n",
    "                    \"Reviews\" : [], \"rating\":{\"Five_star\":0, \n",
    "                                              \"Four_star\":0,\n",
    "                                              \"Three_star\":0,\n",
    "                                              \"Two_star\":0,\n",
    "                                              \"One_star\":0}}\n",
    "match_list = rbf.find({\"asin\":{\"$in\": [id_list.keys()[0]]}})\n",
    "\n",
    "for i in match_list:\n",
    "    beauty_item_info[\"Reviews\"].append(tb(i['reviewText']))\n",
    "    if i['overall'] == 5.0:\n",
    "        beauty_item_info[\"rating\"][\"Five_star\"] += 1\n",
    "    elif i['overall'] == 4.0:\n",
    "        beauty_item_info[\"rating\"][\"Four_star\"] += 1\n",
    "    elif i['overall'] == 3.0:\n",
    "        beauty_item_info[\"rating\"][\"Three_star\"] += 1\n",
    "    elif i['overall'] == 2.0:\n",
    "        beauty_item_info[\"rating\"][\"Two_star\"] += 1\n",
    "    else:\n",
    "        beauty_item_info[\"rating\"][\"One_star\"] += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TF-IDF method\n",
    "\n",
    "tf(word, blob) computes \"term frequency\" which is the number of times a word appears in a document blob, normalized by dividing by the total number of words in blob. We use TextBlob for breaking up the text into words and getting the word counts.\n",
    "\n",
    "n_containing(word, bloblist) returns the number of documents containing word. A generator expression is passed to the sum() function.\n",
    "\n",
    "idf(word, bloblist) computes \"inverse document frequency\" which measures how common a word is among all documents in bloblist. The more common a word is, the lower its idf. We take the ratio of the total number of documents to the number of documents containing word, then take the log of that. Add 1 to the divisor to prevent division by zero.\n",
    "tfidf(word, blob, bloblist) computes the TF-IDF score. It is simply the product of tf and idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Sentiment(polarity=0.3722222222222222, subjectivity=0.6432098765432098)\n",
      "1 Sentiment(polarity=0.2, subjectivity=0.6)\n"
     ]
    }
   ],
   "source": [
    "for i, blob in enumerate(beauty_item_info['Reviews']):\n",
    "    print i, blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextBlob(\"I just started using this, so I'm not sure yet of the long-term effects, but overall it's a great moisturizer.  I'm fairly picky about moisturizers, since I tend to be really oily (my whole face, too...lucky me).  This one seems like it might be a winner.  It absorbed nicely and my skin did look and feel great after using it. It did lose one star, though, because of the price- it's a bit steep.\"),\n",
       " TextBlob(\"I bought it for a collagen moisturizer and immediately found it cleared my breakouts. I still use an under eye cream since I am 56 but this cream is miraculous. It soaks in so fast you can't believe it and it not greasy or shiny for someone with oily skin.\")]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beauty_item_info['Reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "{u'and': -0.010264939445776314, u'winner': 0.0, u'just': 0.0, u'be': -0.010264939445776314, u'feel': 0.0, u'look': 0.0, u'it': -0.030794818337328944, u'one': -0.010264939445776314, u'because': 0.0, u'skin': -0.005132469722888157, u'star': 0.0, u'tend': 0.0, u'moisturizer': -0.005132469722888157, u'really': 0.0, u'to': 0.0, u'since': -0.005132469722888157, u'seems': 0.0, u'yet': 0.0, u'started': 0.0, u'absorbed': 0.0, u'whole': 0.0, u'bit': 0.0, u'This': 0.0, u'might': 0.0, u'oily': -0.005132469722888157, u'too': 0.0, u'fairly': 0.0, u'sure': 0.0, u\"'s\": 0.0, u'steep': 0.0, u'though': 0.0, u'I': -0.02052987889155263, u'moisturizers': 0.0, u'price': 0.0, u'after': 0.0, u'overall': 0.0, u'about': 0.0, u'but': -0.005132469722888157, u'lucky': 0.0, u'me': -0.005132469722888157, u'effects': 0.0, u'not': -0.005132469722888157, u'using': 0.0, u\"'m\": 0.0, u'like': 0.0, u'a': -0.015397409168664472, u'great': 0.0, u'picky': 0.0, u'this': -0.010264939445776314, u'of': 0.0, u'It': -0.030794818337328944, u'face': 0.0, u'nicely': 0.0, u'so': -0.005132469722888157, u'lose': 0.0, u'long-term': 0.0, u'did': 0.0, u'the': 0.0, u'my': -0.010264939445776314}\n",
      "\tWord: winner, TF-IDF: 0.0\n",
      "\tWord: just, TF-IDF: 0.0\n",
      "\tWord: feel, TF-IDF: 0.0\n",
      "Top words in document 2\n",
      "{u'and': -0.01590059247482998, u'is': -0.00795029623741499, u'breakouts': 0.0, u'am': 0.0, u'it': -0.039751481187074944, u'an': -0.00795029623741499, u'soaks': 0.0, u'someone': 0.0, u'in': -0.00795029623741499, u'still': 0.0, u'cream': 0.0, u'use': -0.00795029623741499, u'believe': 0.0, u'eye': 0.0, u'for': 0.0, u'since': -0.00795029623741499, u'fast': 0.0, u'under': 0.0, u'so': -0.00795029623741499, u'you': 0.0, u'ca': -0.00795029623741499, u'bought': 0.0, u'collagen': 0.0, u'I': -0.023850888712244965, u'but': -0.00795029623741499, u'not': -0.00795029623741499, u'immediately': 0.0, u'moisturizer': -0.00795029623741499, u'cleared': 0.0, u'with': 0.0, u'greasy': 0.0, u'a': -0.00795029623741499, u'this': -0.00795029623741499, u'shiny': 0.0, u'56': 0.0, u'It': -0.039751481187074944, u'oily': -0.00795029623741499, u\"n't\": 0.0, u'miraculous': 0.0, u'skin': -0.00795029623741499, u'found': 0.0, u'my': -0.00795029623741499, u'or': -0.00795029623741499}\n",
      "\tWord: breakouts, TF-IDF: 0.0\n",
      "\tWord: am, TF-IDF: 0.0\n",
      "\tWord: soaks, TF-IDF: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, blob in enumerate(beauty_item_info['Reviews']):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, beauty_item_info['Reviews']) for word in blob.words}\n",
    "    print scores\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:3]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Based on the above analysis, we can see that it's not very helpful to look at TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beauty_item_info = {id_list.keys()[0] : id_list.values()[0], \n",
    "                    \"Reviews\" : [], \"rating\":{\"Five_star\":0, \n",
    "                                              \"Four_star\":0,\n",
    "                                              \"Three_star\":0,\n",
    "                                              \"Two_star\":0,\n",
    "                                              \"One_star\":0}}\n",
    "match_list = rbf.find({\"asin\":{\"$in\": [id_list.keys()[0]]}})\n",
    "\n",
    "for i in match_list:\n",
    "    beauty_item_info[\"Reviews\"].append(i['reviewText'])\n",
    "    if i['overall'] == 5.0:\n",
    "        beauty_item_info[\"rating\"][\"Five_star\"] += 1\n",
    "    elif i['overall'] == 4.0:\n",
    "        beauty_item_info[\"rating\"][\"Four_star\"] += 1\n",
    "    elif i['overall'] == 3.0:\n",
    "        beauty_item_info[\"rating\"][\"Three_star\"] += 1\n",
    "    elif i['overall'] == 2.0:\n",
    "        beauty_item_info[\"rating\"][\"Two_star\"] += 1\n",
    "    else:\n",
    "        beauty_item_info[\"rating\"][\"One_star\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "for i in beauty_item_info['Reviews']:\n",
    "    text += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100 #number of words to consider\n",
    "Cluster_threshold = 5 #distance between two words to consider\n",
    "Top_sentences = 5 #number of sentences to return for a \"top n\" summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _score_sentences(sentences, important_words,Cluster_threshold = 5):\n",
    "    scores = []\n",
    "    sentence_idx = -1\n",
    "    \n",
    "    #word_tokenize(s) split a sentence and find all the words and punctuations\n",
    "    for s in [nltk.tokenize.word_tokenize(s) for s in sentences]:\n",
    "        sentence_idx += 1\n",
    "        word_idx =[]\n",
    "        \n",
    "        # This function check whether any important words occur in the sentence\n",
    "        # if  there is, record the location of the important word in the sentence\n",
    "        for w in important_words:\n",
    "            try:\n",
    "                word_idx.append(s.index(w))\n",
    "            except ValueError, e:\n",
    "                pass\n",
    "        word_idx.sort()\n",
    "        \n",
    "        #If there is no important words in the sentence, skip the rest of the loop\n",
    "        #and goes on to next sentence\n",
    "        if len(word_idx) == 0 : continue\n",
    "        \n",
    "        #compute clusters by using a max distance threshold for any two consecutive words\n",
    "        clusters = []\n",
    "        cluster = [word_idx[0]]\n",
    "        \n",
    "        i = 1\n",
    "        while i < len(word_idx):\n",
    "            if word_idx[i] - word_idx[i-1] < Cluster_threshold:\n",
    "                cluster.append(word_idx[i])\n",
    "            else:\n",
    "                clusters.append(cluster[:])\n",
    "                cluster = [word_idx[i]]\n",
    "            i += 1\n",
    "        clusters.append(cluster)\n",
    "        \n",
    "        #now score each cluster. The max score for any give cluster is the score for the \n",
    "        #sentence\n",
    "        \n",
    "        max_cluster_score = 0\n",
    "        for c in clusters:\n",
    "            num_important_words_in_cluster = len(c)\n",
    "            total_words_in_cluster = c[-1] - c[0] + 1\n",
    "            score = 1.0 * num_important_words_in_cluster\\\n",
    "                    *(num_important_words_in_cluster/total_words_in_cluster)\n",
    "            \n",
    "            if score > max_cluster_score:\n",
    "                max_cluster_score = score \n",
    "        score.append(sentence_idx,score)\n",
    "    return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def amazon_rating(x1,x2,x3,x4,x5):\n",
    "    return (x1+2*x2+3*x3+4*x4+5*x5)/float(x1+x2+x3+x4+x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 shades rating 3.47656102918\n",
      "twightlight rating 4.12725696952\n",
      "the hobbit rating 4.69792682927\n",
      "daughter of the forest 4.47708333333\n",
      "best seller of 2014 4.41966048164\n",
      "divergent 4.52524465651\n",
      "eragon 3.95181718062\n",
      "to kill a mocking bird 4.67559626685\n"
     ]
    }
   ],
   "source": [
    "print \"50 shades rating\", amazon_rating(7708,2732,2970,3584,14876)\n",
    "print \"twightlight rating\", amazon_rating(802,349,503,781,4488)\n",
    "print \"the hobbit rating\", amazon_rating(141,104,265,1071,6619)\n",
    "print \"daughter of the forest\", amazon_rating(20,20,19,73,348)\n",
    "print \"best seller of 2014\", amazon_rating(100,108,166,414,1745)\n",
    "print \"divergent\", amazon_rating(411,519,1316,3918,14375)\n",
    "print \"eragon\", amazon_rating(443,267,331,572,2019)\n",
    "print \"to kill a mocking bird\", amazon_rating(141,96,184,657,4708)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_rating(x1,x2,x3,x4,x5,alpha,beta):\n",
    "    return ((x1+2*x2+3*x3+4*x4+5*x5)+alpha*beta)/(float(x1+x2+x3+x4+x5)+beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 shades rating 3.47507037848\n",
      "twightlight rating 4.11120603731\n",
      "the hobbit rating 4.67746987952\n",
      "daughter of the forest 4.2224137931\n",
      "best seller of 2014 4.36574249905\n",
      "divergent 4.51785454722\n",
      "eragon 3.92631296892\n",
      "to kill a mocking bird 4.64712878016\n"
     ]
    }
   ],
   "source": [
    "print \"50 shades rating\", smooth_rating(7708,2732,2970,3584,14876,3,100)\n",
    "print \"twightlight rating\", smooth_rating(802,349,503,781,4488,3,100)\n",
    "print \"the hobbit rating\", smooth_rating(141,104,265,1071,6619,3,100)\n",
    "print \"daughter of the forest\", smooth_rating(20,20,19,73,348,3,100)\n",
    "print \"best seller of 2014\", smooth_rating(100,108,166,414,1745,3,100)\n",
    "print \"divergent\", smooth_rating(411,519,1316,3918,14375,3,100)\n",
    "print \"eragon\", smooth_rating(443,267,331,572,2019,3,100)\n",
    "print \"to kill a mocking bird\", smooth_rating(141,96,184,657,4708,3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_extreme_rating(x1,x2,x3,x4,x5,alpha,beta):\n",
    "    numer = (2*x1+2*x2+3*x3+4*x4+10*x5)+alpha*beta\n",
    "    denom = float(2*x1+x2+x3+x4+2*x5+beta)\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 shades rating 3.54118854713\n",
      "twightlight rating 4.23251847641\n",
      "the hobbit rating 4.78479415671\n",
      "daughter of the forest 4.43987341772\n",
      "best seller of 2014 4.53774006253\n",
      "divergent 4.67268877911\n",
      "eragon 4.06700032289\n",
      "to kill a mocking bird 4.75398230088\n"
     ]
    }
   ],
   "source": [
    "print \"50 shades rating\", weight_extreme_rating(7708,2732,2970,3584,14876,3,100)\n",
    "print \"twightlight rating\", weight_extreme_rating(802,349,503,781,4488,3,100)\n",
    "print \"the hobbit rating\", weight_extreme_rating(141,104,265,1071,6619,3,100)\n",
    "print \"daughter of the forest\", weight_extreme_rating(20,20,19,73,348,3,100)\n",
    "print \"best seller of 2014\", weight_extreme_rating(100,108,166,414,1745,3,100)\n",
    "print \"divergent\", weight_extreme_rating(411,519,1316,3918,14375,3,100)\n",
    "print \"eragon\", weight_extreme_rating(443,267,331,572,2019,3,100)\n",
    "print \"to kill a mocking bird\", weight_extreme_rating(141,96,184,657,4708,3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strict_rating(x1,x2,x3,x4,x5,alpha,beta):\n",
    "    numer = (2*x1+4*x2+3*x3+4*x4+5*x5)+alpha*beta\n",
    "    denom = float(2*x1+x2+x3+x4+x5+beta)\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 shades rating 2.7851686152\n",
      "twightlight rating 3.61365480468\n",
      "the hobbit rating 4.58086693079\n",
      "daughter of the forest 4.07903225806\n",
      "best seller of 2014 4.20437698553\n",
      "divergent 4.43148035972\n",
      "eragon 3.48051104374\n",
      "to kill a mocking bird 4.51151102464\n"
     ]
    }
   ],
   "source": [
    "print \"50 shades rating\", strict_rating(7708,2732,2970,3584,14876,3,100)\n",
    "print \"twightlight rating\", strict_rating(802,349,503,781,4488,3,100)\n",
    "print \"the hobbit rating\", strict_rating(141,104,265,1071,6619,3,100)\n",
    "print \"daughter of the forest\", strict_rating(20,20,19,73,348,3,100)\n",
    "print \"best seller of 2014\", strict_rating(100,108,166,414,1745,3,100)\n",
    "print \"divergent\", strict_rating(411,519,1316,3918,14375,3,100)\n",
    "print \"eragon\", strict_rating(443,267,331,572,2019,3,100)\n",
    "print \"to kill a mocking bird\", strict_rating(141,96,184,657,4708,3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.06906906907\n",
      "3.77725118483\n",
      "4.19783197832\n",
      "3.52302631579\n",
      "3.42258748674\n"
     ]
    }
   ],
   "source": [
    "print strict_rating(1,0,3,32,193,2.5,100)\n",
    "print strict_rating(0,0,1,6,104,2.5,100)\n",
    "print strict_rating(0,1,7,31,230,2.5,100)\n",
    "print strict_rating(253,184,297,590,2428,2.5,100)\n",
    "print strict_rating(101,64,117,205,895,2.5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strict_rating(x1,x2,x3,x4,x5,alpha,beta):\n",
    "    numer = (3*x1+4*x2+3*x3+4*x4+5*x5)+alpha*beta\n",
    "    denom = float(5*x1+x2+x3+x4+x5+beta)\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.stem.snowball.SnowballStemmer at 0x1176bd410>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
